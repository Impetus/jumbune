package com.impetus.jumbune.common.alerts;

import static com.impetus.jumbune.common.alerts.AlertConstants.CAPACITY;
import static com.impetus.jumbune.common.alerts.AlertConstants.CLOSING_BRACKET;
import static com.impetus.jumbune.common.alerts.AlertConstants.DATA_NODE;
import static com.impetus.jumbune.common.alerts.AlertConstants.DATA_NODE_WITH_STORAGE_ID;
import static com.impetus.jumbune.common.alerts.AlertConstants.DEAMON_WENT_DOWN;
import static com.impetus.jumbune.common.alerts.AlertConstants.DISKSPACE_ALERT_MESSAGE;
import static com.impetus.jumbune.common.alerts.AlertConstants.FS_DATASET_STATE;
import static com.impetus.jumbune.common.alerts.AlertConstants.FS_DATASET_STATE2;
import static com.impetus.jumbune.common.alerts.AlertConstants.FS_NAMESYSTEM_BLOCKS_TOTAL;
import static com.impetus.jumbune.common.alerts.AlertConstants.FS_NAMESYSTEM_CAPACITY_TOTAL;
import static com.impetus.jumbune.common.alerts.AlertConstants.FS_NAMESYSTEM_CAPACITY_USED;
import static com.impetus.jumbune.common.alerts.AlertConstants.FS_NAMESYSTEM_STATE_NUM_DEAD_DATA_NODES;
import static com.impetus.jumbune.common.alerts.AlertConstants.FS_NAMESYSTEM_UNDER_REPLICATED_BLOCKS;
import static com.impetus.jumbune.common.alerts.AlertConstants.HAS;
import static com.impetus.jumbune.common.alerts.AlertConstants.HDFS_SPACE_USAGE_MESSAGE;
import static com.impetus.jumbune.common.alerts.AlertConstants.NAME_NODE;
import static com.impetus.jumbune.common.alerts.AlertConstants.NODE_S_UNAVAILABLE;
import static com.impetus.jumbune.common.alerts.AlertConstants.NULL;
import static com.impetus.jumbune.common.alerts.AlertConstants.NUM_FAILED_VOLUMES;
import static com.impetus.jumbune.common.alerts.AlertConstants.N_A;
import static com.impetus.jumbune.common.alerts.AlertConstants.REMAINING;
import static com.impetus.jumbune.common.alerts.AlertConstants.STORAGE_ID;
import static com.impetus.jumbune.common.alerts.AlertConstants.UNDER_REPLICATED_BLOCK_MESSAGE;
import static com.impetus.jumbune.common.alerts.AlertConstants.VOLUME_FAILURE_S;
import static org.jumbune.profiling.utils.ProfilerConstants.JMX_URL_POSTFIX;
import static org.jumbune.profiling.utils.ProfilerConstants.JMX_URL_PREFIX;

import java.net.MalformedURLException;
import java.text.SimpleDateFormat;
import java.util.ArrayList;
import java.util.Date;
import java.util.List;
import java.util.Map;
import java.util.Set;

import javax.management.remote.JMXServiceURL;

import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.jumbune.common.beans.cluster.Cluster;
import org.jumbune.common.utils.Constants;
import org.jumbune.common.utils.FileUtil;
import org.jumbune.common.utils.RemotingUtil;
import org.jumbune.profiling.beans.JMXDeamons;
import org.jumbune.profiling.utils.JMXConnectorCache;
import org.jumbune.profiling.utils.JMXConnectorInstance;
import org.jumbune.profiling.utils.ProfilerJMXDump;
import org.jumbune.utils.conf.AdminConfigurationUtil;
import org.jumbune.utils.conf.beans.AlertType;
import org.jumbune.utils.conf.beans.SeverityLevel;
import org.jumbune.utils.exception.JumbuneRuntimeException;

import com.impetus.jumbune.common.beans.Alert;
import com.impetus.jumbune.common.utils.ExtendedConstants;

/**
 * The Class AlertGenerator.
 */
public class AlertGenerator {

	/** The logger. */
	private static final Logger LOGGER = LogManager.getLogger(AlertGenerator.class);

	/**
	 * Gets the alerts.
	 *
	 * @param cluster
	 *            the cluster
	 * @return the alerts
	 * @throws Exception
	 *             the exception
	 */
	@Deprecated
	public List<List<Alert>> getAlerts(Cluster cluster) throws Exception {
		List<List<Alert>> alertList = new ArrayList<List<Alert>>();
		String hadoopDistribution = FileUtil.getClusterInfoDetail(Constants.HADOOP_DISTRIBUTION);
		if (!Constants.MAPR.equalsIgnoreCase(hadoopDistribution)) {
			// configurable DISK_SPACE_UTILIZATION
			alertList.add(getDiskSpaceUsageAlert(cluster));
			// configurable UNDER_REPLICATED_BLOCKS
			alertList.add(getUnderReplicatedBlockAlert(cluster));
			// configurable HDFS_UTILIZATION
			alertList.add(getHDFSSpaceUsageAlert(cluster));
			// non-configurable DN_VOLUME_FAILURE_CHECK
			alertList.add(getDataNodeVolumeFailureAlert(cluster));
			// non-configurable HADOOP_DAEMON_DOWN
			alertList.add(getDataNodeDownAlert(cluster));
			// non-configurable HADOOP_DAEMON_DOWN
			alertList.add(getNodeDownAlert(cluster));
			// non-configurable HADOOP_DAEMON_DOWN
			Alert alert = getNameNodeDownAlert(cluster);
			if (alert != null) {
				List<Alert> list = new ArrayList<Alert>(1);
				list.add(alert);
				alertList.add(list);
			}
		}
		return alertList;
	}

	/**
	 * Gets the data node down alert.
	 *
	 * @param cluster
	 *            the cluster
	 * @return the data node down alert
	 */
	public List<Alert> getDataNodeDownAlert(Cluster cluster) {
		List<String> workers = cluster.getWorkers().getHosts();
		List<Alert> alertList = new ArrayList<Alert>();
		for (String worker : workers) {
			String dataNodeInstance = null;
			dataNodeInstance = RemotingUtil.getDaemonProcessId(cluster, worker, JMXDeamons.DATA_NODE.toString());
			if (dataNodeInstance.isEmpty()) {
				Alert alert = new Alert(ExtendedConstants.CRITICAL_LEVEL, worker, DATA_NODE + DEAMON_WENT_DOWN,
						getDate());
				alertList.add(alert);
			}
		}
		return alertList;
	}

	/**
	 * Gets the disk space usage alert.
	 *
	 * @param cluster
	 *            the cluster
	 * @return the disk space usage alert
	 */
	public List<Alert> getDiskSpaceUsageAlert(Cluster cluster) {

		List<String> workers = cluster.getWorkers().getHosts();
		ProfilerJMXDump jmxDump = new ProfilerJMXDump();
		SeverityLevel severityLevel = AdminConfigurationUtil.getAlertConfiguration(cluster.getClusterName())
				.getConfigurableAlerts().get(AlertType.DISK_SPACE_UTILIZATION);

		List<Alert> alertList = new ArrayList<Alert>();
		Map<String, String> dataNodeJMXStats = null;

		int criticalLevel = severityLevel.getCriticalLevel();
		int warningLevel = severityLevel.getWarningLevel();

		String statName, diskCapacity, remainingCapacity;

		Alert alert = null;

		for (String worker : workers) {
			try {
				dataNodeJMXStats = jmxDump.getAllJMXStats(JMXDeamons.DATA_NODE, worker,
						cluster.getWorkers().getDataNodeJmxPort(), cluster.isJmxPluginEnabled());
			} catch (Exception e) {
				jmxConnectionCacheClear(cluster, worker);
				continue;
			}

			for (Map.Entry<String, String> usableStat : dataNodeJMXStats.entrySet()) {

				statName = usableStat.getKey();

				if (statName.startsWith(FS_DATASET_STATE) && statName.endsWith(CAPACITY)) {

					diskCapacity = dataNodeJMXStats.get(statName);
					remainingCapacity = dataNodeJMXStats.get(statName.replace(CAPACITY, REMAINING));

					if (diskCapacity != null && !diskCapacity.isEmpty() && remainingCapacity != null
							&& !remainingCapacity.isEmpty()) {
						Double diskSpaceUsed = ((Double.parseDouble(diskCapacity)
								- Double.parseDouble(remainingCapacity)) / Double.parseDouble(diskCapacity) * 100);

						if (diskSpaceUsed >= criticalLevel) {
							alert = new Alert(ExtendedConstants.CRITICAL_LEVEL, worker,
									getDiskStorageId(statName) + DISKSPACE_ALERT_MESSAGE, getDate());
							alertList.add(alert);
						} else if ((diskSpaceUsed < criticalLevel) && (diskSpaceUsed >= warningLevel)) {
							alert = new Alert(ExtendedConstants.WARNING_LEVEL, worker,
									getDiskStorageId(statName) + DISKSPACE_ALERT_MESSAGE, getDate());
							alertList.add(alert);
						}
					}
				}
			}
		}
		return alertList;
	}

	private String getDiskStorageId(String statName) {
		String[] splits = statName.split(FS_DATASET_STATE2);
		String id = null;
		if (splits.length == 2) {
			String lastSplit = splits[1];
			id = lastSplit.substring(0, lastSplit.indexOf(CAPACITY));
		}

		if (id == null || id.isEmpty() || id.equals(NULL)) {
			return Constants.EMPTY_STRING;
		}
		return STORAGE_ID + id + CLOSING_BRACKET;
	}

	/**
	 * Gets the data node volume failure alert.
	 *
	 * @param cluster
	 *            the cluster
	 * @return the data node volume failure alert
	 */
	public List<Alert> getDataNodeVolumeFailureAlert(Cluster cluster) {

		List<String> workers = cluster.getWorkers().getHosts();
		ProfilerJMXDump jmxDump = new ProfilerJMXDump();
		List<Alert> alertList = new ArrayList<Alert>();
		Map<String, String> dataNodeJMXStats = null;

		for (String worker : workers) {
			try {
				dataNodeJMXStats = jmxDump.getAllJMXStats(JMXDeamons.DATA_NODE, worker,
						cluster.getWorkers().getDataNodeJmxPort(), cluster.isJmxPluginEnabled());
			} catch (Exception e) {
				jmxConnectionCacheClear(cluster, worker);
				continue;
			}

			if (dataNodeJMXStats != null) {
				Set<String> keys = dataNodeJMXStats.keySet();
				for (String key : keys) {
					if (key.startsWith(FS_DATASET_STATE) && key.endsWith(NUM_FAILED_VOLUMES)) {
						String storageId = Constants.EMPTY_STRING;
						String[] splits = key.split(FS_DATASET_STATE2);
						if (splits.length == 2) {
							String lastSplit = splits[1];
							storageId = lastSplit.substring(0, lastSplit.indexOf(NUM_FAILED_VOLUMES));
						}
						if (storageId.isEmpty() || storageId.equals(NULL)) {
							storageId = N_A;
						}
						Double numFailedVolumes = Double.parseDouble(dataNodeJMXStats.get(key));
						if (numFailedVolumes > 0) {
							Alert alert = new Alert(ExtendedConstants.CRITICAL_LEVEL, worker,
									DATA_NODE_WITH_STORAGE_ID + storageId + HAS + numFailedVolumes + VOLUME_FAILURE_S,
									getDate());
							alertList.add(alert);
						}

					}
				}
			}
		}
		return alertList;
	}

	/**
	 * Jmx connection cache clear.
	 *
	 * @param cluster
	 *            the cluster
	 * @param worker
	 *            the worker
	 */
	private void jmxConnectionCacheClear(Cluster cluster, String worker) {
		JMXConnectorCache cache = JMXConnectorCache.getJMXCacheInstance();
		JMXServiceURL url;
		try {
			url = new JMXServiceURL(JMX_URL_PREFIX + worker + Constants.COLON
					+ cluster.getWorkers().getDataNodeJmxPort() + JMX_URL_POSTFIX);
			cache.remove(url);
			cache.clear();
			JMXConnectorInstance.nullifyConnector();
		} catch (MalformedURLException e) {
			LOGGER.info(JumbuneRuntimeException.throwException(e.getStackTrace()));
		}
	}

	/**
	 * Gets the under replicated block alert.
	 *
	 * @param cluster
	 *            the cluster
	 * @return the under replicated block alert
	 */
	public List<Alert> getUnderReplicatedBlockAlert(Cluster cluster) {

		ProfilerJMXDump jmxDump = new ProfilerJMXDump();
		List<Alert> alertList = new ArrayList<Alert>(1);

		SeverityLevel severityLevel = AdminConfigurationUtil.getAlertConfiguration(cluster.getClusterName())
				.getConfigurableAlerts().get(AlertType.UNDER_REPLICATED_BLOCKS);

		Map<String, String> nameNodeStats = null;

		int criticalLevel = severityLevel.getCriticalLevel();
		int warningLevel = severityLevel.getWarningLevel();

		try {
			nameNodeStats = jmxDump.getAllJMXStats(JMXDeamons.NAME_NODE, cluster.getNameNode(),
					cluster.getNameNodes().getNameNodeJmxPort(), cluster.isJmxPluginEnabled());
		} catch (Exception e) {
			jmxConnectionCacheClear(cluster, cluster.getNameNode());
			return alertList;
		}
		if (nameNodeStats != null) {
			Double blockTotal = Double.parseDouble(nameNodeStats.get(FS_NAMESYSTEM_BLOCKS_TOTAL));
			Double underReplicatedBlock = Double.parseDouble(nameNodeStats.get(FS_NAMESYSTEM_UNDER_REPLICATED_BLOCKS));

			if (blockTotal > 0) {
				Double underReplicatedBlockPercent = (underReplicatedBlock / blockTotal) * 100;
				if (underReplicatedBlockPercent >= criticalLevel) {
					Alert alert = new Alert(ExtendedConstants.CRITICAL_LEVEL, ExtendedConstants.ALL,
							underReplicatedBlock + UNDER_REPLICATED_BLOCK_MESSAGE, getDate());
					alertList.add(alert);
				} else if (underReplicatedBlockPercent >= warningLevel && underReplicatedBlockPercent < criticalLevel) {
					Alert alert = new Alert(ExtendedConstants.WARNING_LEVEL, ExtendedConstants.ALL,
							underReplicatedBlock + UNDER_REPLICATED_BLOCK_MESSAGE, getDate());
					alertList.add(alert);
				}
			}

		}
		return alertList;
	}

	/**
	 * Gets the node down alert.
	 *
	 * @param cluster
	 *            the cluster
	 * @return the node down alert
	 */
	public List<Alert> getNodeDownAlert(Cluster cluster) {

		ProfilerJMXDump jmxDump = new ProfilerJMXDump();
		List<Alert> alertList = new ArrayList<Alert>(1);

		Map<String, String> nameNodeStats = null;

		try {
			nameNodeStats = jmxDump.getAllJMXStats(JMXDeamons.NAME_NODE, cluster.getNameNode(),
					cluster.getNameNodes().getNameNodeJmxPort(), cluster.isJmxPluginEnabled());
		} catch (Exception e) {
			jmxConnectionCacheClear(cluster, cluster.getNameNode());
		}
		if (nameNodeStats != null) {
			Integer nodeDown = Integer.parseInt(nameNodeStats.get(FS_NAMESYSTEM_STATE_NUM_DEAD_DATA_NODES));
			if (nodeDown > 0) {
				Alert alert = new Alert(ExtendedConstants.WARNING_LEVEL, ExtendedConstants.HYPHEN,
						nodeDown + NODE_S_UNAVAILABLE, getDate());
				alertList.add(alert);
			}

		}
		return alertList;
	}

	/**
	 * Gets the HDFS space usage alert.
	 *
	 * @param cluster
	 *            the cluster
	 * @return the HDFS space usage alert
	 */
	public List<Alert> getHDFSSpaceUsageAlert(Cluster cluster) {

		ProfilerJMXDump jmxDump = new ProfilerJMXDump();
		List<Alert> alertList = new ArrayList<Alert>(2);
		SeverityLevel severityLevel = AdminConfigurationUtil.getAlertConfiguration(cluster.getClusterName())
				.getConfigurableAlerts().get(AlertType.HDFS_UTILIZATION);

		Map<String, String> nameNodeStats = null;

		int hdfsCriticalLevel = severityLevel.getCriticalLevel();
		int hdfsWarningLevel = severityLevel.getWarningLevel();

		try {
			nameNodeStats = jmxDump.getAllJMXStats(JMXDeamons.NAME_NODE, cluster.getNameNode(),
					cluster.getNameNodes().getNameNodeJmxPort(), cluster.isJmxPluginEnabled());
		} catch (Exception e) {
			jmxConnectionCacheClear(cluster, cluster.getNameNode());
			return alertList;
		}
		if (nameNodeStats != null) {

			Double hdfsCapacityUtilization = (Double.parseDouble(nameNodeStats.get(FS_NAMESYSTEM_CAPACITY_USED))
					/ Double.parseDouble(nameNodeStats.get(FS_NAMESYSTEM_CAPACITY_TOTAL))) * 100;

			if (hdfsCapacityUtilization >= hdfsCriticalLevel) {
				Alert alert = new Alert(ExtendedConstants.CRITICAL_LEVEL, ExtendedConstants.ALL,
						HDFS_SPACE_USAGE_MESSAGE, getDate());
				alertList.add(alert);
			} else if (hdfsCapacityUtilization >= hdfsWarningLevel && hdfsCapacityUtilization < hdfsCriticalLevel) {
				Alert alert = new Alert(ExtendedConstants.WARNING_LEVEL, ExtendedConstants.ALL,
						HDFS_SPACE_USAGE_MESSAGE, getDate());
				alertList.add(alert);
			}
		}
		return alertList;
	}

	/**
	 * Gets the name node down alert.
	 *
	 * @param cluster
	 *            the cluster
	 * @return the name node down alert
	 */
	public Alert getNameNodeDownAlert(Cluster cluster) {

		String nameNodeInstance = null;
		nameNodeInstance = RemotingUtil.getDaemonProcessId(cluster, cluster.getNameNode(),
				JMXDeamons.NAME_NODE.toString());
		if (nameNodeInstance.isEmpty()) {
			return new Alert(ExtendedConstants.CRITICAL_LEVEL, cluster.getNameNode(), NAME_NODE + DEAMON_WENT_DOWN,
					getDate());
		}

		return null;
	}

	/**
	 * Gets the current time and date.
	 *
	 * @return the date
	 */
	private String getDate() {
		Date date = new Date(System.currentTimeMillis());
		SimpleDateFormat sdf = new SimpleDateFormat(ExtendedConstants.TIME_FORMAT);
		return sdf.format(date);
	}

}